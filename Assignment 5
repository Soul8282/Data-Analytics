# Load necessary libraries
library(dplyr)
library(ggplot2)
library(scales)

                                          #PART 1B

nyc_data <- read.csv("C:\\Users\\barry\\Downloads\\NYC_Citywide_Annualized_Calendar_Sales_Update_20241129.csv", header = TRUE)

# Filter the data for Manhattan
manhattan_data <- nyc_data %>%
  filter(BOROUGH == "1")

write.csv(manhattan_data, "manhattan_data.csv", row.names = FALSE)

head(manhattan_data)

manhattan_data$SALE.PRICE <- gsub("[^0-9.]", "", manhattan_data$SALE.PRICE) 
manhattan_data$SALE.PRICE <- as.numeric(manhattan_data$SALE.PRICE)        
manhattan_data_clean <- manhattan_data %>% filter(!is.na(SALE.PRICE) & SALE.PRICE > 0)

# Sale Price Distribution
# Plot histogram for Sale Price
ggplot(manhattan_data_clean, aes(x = SALE.PRICE)) +
  geom_histogram(bins = 50, fill = "blue", color = "black") +
  scale_x_log10() +  # Log scale for better visualization
  labs(title = "Sale Price Distribution (Log Scale)", x = "Sale Price (Log Scale)", y = "Count") +
  theme_minimal()

# Calculate IQR, Q1, and Q3
Q1 <- quantile(manhattan_data_clean$SALE.PRICE, 0.25, na.rm = TRUE)
Q3 <- quantile(manhattan_data_clean$SALE.PRICE, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1

lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR

#Identify outliers
manhattan_data_clean <- manhattan_data_clean %>%
  mutate(Outlier = ifelse(SALE.PRICE < lower_bound | SALE.PRICE > upper_bound, "Outlier", "Non-Outlier"))


#Plot Histogram with Outliers Highlighted
ggplot(manhattan_data_clean, aes(x = SALE.PRICE)) +
  # Histogram
  geom_histogram(aes(fill = Outlier), bins = 50, color = "black", alpha = 0.7) +
  # Log scale and better axis labels
  scale_x_log10(labels = scales::comma) +
  scale_fill_manual(values = c("Outlier" = "red", "Non-Outlier" = "blue")) +
  # Add vertical lines for IQR bounds
  geom_vline(xintercept = lower_bound, color = "darkgreen", linetype = "dashed") +
  geom_vline(xintercept = upper_bound, color = "darkgreen", linetype = "dashed") +
  # Labels and titles
  labs(
    title = "Sale Price Distribution, Manhattan",
    x = "Sale Price (Log Scale, in $)",
    y = "Number of Properties",
    fill = "Category"
  ) +
  theme_minimal()


# Plot histogram with outliers highlighted
ggplot(manhattan_data_clean, aes(x = SALE.PRICE, fill = Outlier)) +
  # Histogram
  geom_histogram(bins = 50, color = "black", alpha = 0.7) +
  # Linear scale with limited x-axis range
  scale_x_continuous(limits = c(0, 10000000), labels = scales::comma) +
  # Define fill colors for outliers and non-outliers
  scale_fill_manual(values = c("Non-Outlier" = "blue", "Outlier" = "red")) +
  # Labels and titles
  labs(
    title = "Sale Price Distribution with Outliers Highlighted (Linear Scale, Manhattan)",
    x = "Sale Price (in $)",
    y = "Number of Properties",
    fill = "Category"
  ) +
  theme_minimal()

# Convert Sale Date to Date format
manhattan_data_clean$SALE.DATE <- as.Date(manhattan_data_clean$SALE.DATE, format = "%m/%d/%Y")
manhattan_data_clean$YEAR <- format(manhattan_data_clean$SALE.DATE, "%Y")

# Aggregate average sale price by year
yearly_trends <- manhattan_data_clean %>%
  group_by(YEAR) %>%
  summarize(Average_Price = mean(SALE.PRICE, na.rm = TRUE))

# Plot Sale Price trends over time
ggplot(yearly_trends, aes(x = as.numeric(YEAR), y = Average_Price)) +
  geom_line(color = "blue") +
  geom_point(size = 2) +
  scale_y_log10(labels = scales::comma) +
  labs(title = "Average Sale Price Over Time", x = "Year", y = "Average Sale Price (Log Scale)") +
  theme_minimal()

                                      #PART 1C
library(dplyr)
library(ggplot2)
library(caret)

# Load your dataset
data <- read.csv("C:\\Users\\barry\\Downloads\\manhattan_data.csv", stringsAsFactors = TRUE)
# Safely identify problematic rows
problematic_rows <- data %>%
  filter(
    grepl("[^0-9,]", GROSS.SQUARE.FEET) | grepl("[^0-9,]", LAND.SQUARE.FEET)
  )

# Display problematic rows
print(problematic_rows)

# Clean GROSS.SQUARE.FEET and LAND.SQUARE.FEET columns
data_clean <- data %>%
  mutate(
    GROSS.SQUARE.FEET = as.numeric(gsub("[^0-9]", "", GROSS.SQUARE.FEET)), 
    LAND.SQUARE.FEET = as.numeric(gsub("[^0-9]", "", LAND.SQUARE.FEET))   
  ) %>%
  filter(
    !is.na(SALE.PRICE) & SALE.PRICE > 0,             
    !is.na(GROSS.SQUARE.FEET) & GROSS.SQUARE.FEET > 0,  
    !is.na(LAND.SQUARE.FEET) & LAND.SQUARE.FEET > 0     
  )

print(summary(data_clean))


# Train-Test Split
set.seed(123)
train_index <- createDataPartition(borough_data$SALE.PRICE, p = 0.7, list = FALSE)
train_data <- borough_data[train_index, ]
test_data <- borough_data[-train_index, ]

# Build Initial Multivariate Regression Model
model <- lm(
  SALE.PRICE ~ GROSS.SQUARE.FEET + LAND.SQUARE.FEET + YEAR.BUILT + TOTAL.UNITS,
  data = train_data
)

# Model Summary
cat("Model Summary:\n")
print(summary(model))

# Predictions on Test Data
test_data$Predicted.Price <- predict(model, newdata = test_data)


# Calculate IQR 
iqr_sale_price <- IQR(test_data$SALE.PRICE, na.rm = TRUE)
iqr_predicted_price <- IQR(test_data$Predicted.Price, na.rm = TRUE)

# Calculate bounds for Sale Price
lower_bound_sale_price <- quantile(test_data$SALE.PRICE, 0.25, na.rm = TRUE) - 1.5 * iqr_sale_price
upper_bound_sale_price <- quantile(test_data$SALE.PRICE, 0.75, na.rm = TRUE) + 1.5 * iqr_sale_price

# Calculate bounds for Predicted Price
lower_bound_predicted_price <- quantile(test_data$Predicted.Price, 0.25, na.rm = TRUE) - 1.5 * iqr_predicted_price
upper_bound_predicted_price <- quantile(test_data$Predicted.Price, 0.75, na.rm = TRUE) + 1.5 * iqr_predicted_price

# Filter out rows where Sale Price or Predicted Price are outliers
filtered_test_data <- test_data %>%
  filter(
    SALE.PRICE >= lower_bound_sale_price & SALE.PRICE <= upper_bound_sale_price,
    Predicted.Price >= lower_bound_predicted_price & Predicted.Price <= upper_bound_predicted_price
  )

# Visualization: Predicted vs Actual Sale Prices (without outliers)
ggplot(filtered_test_data, aes(x = SALE.PRICE, y = Predicted.Price)) +
  geom_point(color = "blue", alpha = 0.5) +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(
    title = "Predicted vs Actual Sale Prices (Without Outliers)",
    x = "Actual Sale Price",
    y = "Predicted Sale Price"
  ) +
  theme_minimal()

# Subset 1: Building Class Example
subset1 <- test_data %>% filter(BUILDING.CLASS.AT.TIME.OF.SALE == "O2")
subset1$Predicted.Price <- predict(model, newdata = subset1)
R2_subset1 <- cor(subset1$SALE.PRICE, subset1$Predicted.Price)^2
cat("R-squared on Subset 1 (Building Class O2):", R2_subset1, "\n")

# Subset 2: Properties with more than 10,000 square feet
subset2 <- test_data %>% filter(GROSS.SQUARE.FEET > 10000)

# Generate predictions
subset2$Predicted.Price <- predict(model, newdata = subset2)

# Remove rows with NA in SALE.PRICE or Predicted.Price to avoid R-squared errors
subset2_clean <- subset2 %>%
  filter(!is.na(SALE.PRICE) & !is.na(Predicted.Price))

# Ensure that the SALE.PRICE and Predicted.Price are numeric
subset2_clean$SALE.PRICE <- as.numeric(subset2_clean$SALE.PRICE)
subset2_clean$Predicted.Price <- as.numeric(subset2_clean$Predicted.Price)

# Calculate R-squared
R2_subset2 <- cor(subset2_clean$SALE.PRICE, subset2_clean$Predicted.Price)^2
cat("R-squared on Subset 2 (Properties with Gross Square Feet > 10,000):", R2_subset2, "\n")

                                          #1D
library(dplyr)
library(caret)
library(ggplot2)
library(e1071)  

data <- read.csv("C:\\Users\\barry\\Downloads\\manhattan_data.csv", stringsAsFactors = TRUE)

# Clean GROSS.SQUARE.FEET and LAND.SQUARE.FEET columns
data_clean <- data %>%
  mutate(
    GROSS.SQUARE.FEET = as.numeric(gsub("[^0-9]", "", GROSS.SQUARE.FEET)),  
    LAND.SQUARE.FEET = as.numeric(gsub("[^0-9]", "", LAND.SQUARE.FEET))    
  ) %>%
  filter(
    !is.na(SALE.PRICE) & SALE.PRICE > 0,           
    !is.na(GROSS.SQUARE.FEET) & GROSS.SQUARE.FEET > 0,  
    !is.na(LAND.SQUARE.FEET) & LAND.SQUARE.FEET > 0     
  )

# Train-Test Split
set.seed(123)
train_index <- createDataPartition(data_clean$SALE.PRICE, p = 0.7, list = FALSE)
train_data <- data_clean[train_index, ]
test_data <- data_clean[-train_index, ]

# Prepare features and labels for training
train_features <- train_data %>%
  select(GROSS.SQUARE.FEET, LAND.SQUARE.FEET, TOTAL.UNITS, YEAR.BUILT)
train_labels <- train_data$BUILDING.CLASS.CATEGORY
test_features <- test_data %>%
  select(GROSS.SQUARE.FEET, LAND.SQUARE.FEET, TOTAL.UNITS, YEAR.BUILT)
test_labels <- test_data$BUILDING.CLASS.CATEGORY

# Remove rows with missing values in train and test datasets
train_data_clean <- na.omit(cbind(train_features, train_labels))
test_data_clean <- na.omit(cbind(test_features, test_labels))

# Extract cleaned features and labels
train_features_clean <- train_data_clean[, -ncol(train_data_clean)]
train_labels_clean <- train_data_clean[, ncol(train_data_clean)]
test_features_clean <- test_data_clean[, -ncol(test_data_clean)]
test_labels_clean <- test_data_clean[, ncol(test_data_clean)]

# Ensure labels are factors for classification tasks
train_labels_clean <- factor(train_labels_clean)
test_labels_clean <- factor(test_labels_clean)

# k-NN Model (Existing Model)
knn_predictions <- knn(
  train = train_features_clean, 
  test = test_features_clean, 
  cl = train_labels_clean, 
  k = 5
)

# Naïve Bayes Model
nb_model <- naiveBayes(
  train_features_clean, 
  train_labels_clean
)

# Make predictions with Naïve Bayes
nb_predictions <- predict(nb_model, newdata = test_features_clean)

# Create Confusion Matrices
knn_conf_matrix <- confusionMatrix(knn_predictions, test_labels_clean)
nb_conf_matrix <- confusionMatrix(nb_predictions, test_labels_clean)

# Display confusion matrices for k-NN and Naïve Bayes
cat("\nk-NN Confusion Matrix:\n")
print(knn_conf_matrix)

cat("\nNaïve Bayes Confusion Matrix:\n")
print(nb_conf_matrix)

# Visualizations for Naïve Bayes and k-NN

# Boxplot of Actual vs Predicted Sale Prices (Log-Transformed) for k-NN and Naïve Bayes
ggplot() +
  geom_boxplot(aes(x = "Log Actual", y = log(test_data$SALE.PRICE)), fill = "blue", alpha = 0.5) +
  geom_boxplot(aes(x = "Log Predicted (k-NN)", y = log(as.numeric(knn_predictions))), fill = "green", alpha = 0.5) +
  geom_boxplot(aes(x = "Log Predicted (Naïve Bayes)", y = log(as.numeric(nb_predictions))), fill = "red", alpha = 0.5) +
  labs(
    title = "Boxplot of Log-Transformed Actual vs Predicted Sale Prices",
    x = "Type",
    y = "Log of Sale Price"
  ) +
  theme_minimal()

# Residual Density Plot (Actual - Predicted) for k-NN and Naïve Bayes
knn_residuals <- log(test_data$SALE.PRICE) - log(as.numeric(knn_predictions))
nb_residuals <- log(test_data$SALE.PRICE) - log(as.numeric(nb_predictions))

ggplot() +
  geom_density(aes(x = knn_residuals), fill = "blue", alpha = 0.5) +
  geom_density(aes(x = nb_residuals), fill = "red", alpha = 0.5) +
  labs(
    title = "Residual Density Plot (Actual - Predicted)",
    x = "Residuals (Actual - Predicted)",
    y = "Density"
  ) +
  theme_minimal()




                                            #2A

library(dplyr)
library(ggplot2)
library(caret)

data <- read.csv("C:\\Users\\barry\\Downloads\\NYC_Citywide_Annualized_Calendar_Sales_Update_20241129.csv")

data_clean <- data %>%
  mutate(
    GROSS.SQUARE.FEET = as.numeric(gsub("[^0-9]", "", GROSS.SQUARE.FEET)),
    LAND.SQUARE.FEET = as.numeric(gsub("[^0-9]", "", LAND.SQUARE.FEET)),
    SALE.PRICE = as.numeric(gsub("[^0-9]", "", SALE.PRICE))
  ) %>%
  filter(
    !is.na(SALE.PRICE) & SALE.PRICE > 0,
    !is.na(GROSS.SQUARE.FEET) & GROSS.SQUARE.FEET > 0,
    !is.na(LAND.SQUARE.FEET) & LAND.SQUARE.FEET > 0
  )


set.seed(123)  
train_index <- createDataPartition(data_clean$SALE.PRICE, p = 0.7, list = FALSE)
train_data <- data_clean[train_index, ]
test_data <- data_clean[-train_index, ]

model <- lm(SALE.PRICE ~ GROSS.SQUARE.FEET + LAND.SQUARE.FEET + YEAR.BUILT + TOTAL.UNITS, data = train_data)

cat("Model Summary:\n")
print(summary(model))

#Predictions on Test Data
test_data$Predicted.Price <- predict(model, newdata = test_data)

#Visualization of Predicted vs Actual Sale Prices
ggplot(test_data, aes(x = SALE.PRICE, y = Predicted.Price)) +
  geom_point(color = "blue", alpha = 0.5) +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(
    title = "Predicted vs Actual Sale Prices",
    x = "Actual Sale Price",
    y = "Predicted Sale Price"
  ) +
  theme_minimal()

#Calculate Residuals
test_data$Residuals <- test_data$SALE.PRICE - test_data$Predicted.Price

#Visualization of Residuals vs Predicted Prices
ggplot(test_data, aes(x = Predicted.Price, y = Residuals)) +
  geom_point(color = "green", alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Residuals vs Predicted Prices",
    x = "Predicted Sale Price",
    y = "Residuals"
  ) +
  theme_minimal()

                                    #2D
library(dplyr)
library(caret)
library(ggplot2)
library(e1071)  

data <- read.csv("C:\Users\barry\Downloads\NYC_Citywide_Annualized_Calendar_Sales_Update_20241129.csv", stringsAsFactors = TRUE)

# Clean GROSS.SQUARE.FEET and LAND.SQUARE.FEET columns
data_clean <- data %>%
  mutate(
    GROSS.SQUARE.FEET = as.numeric(gsub("[^0-9]", "", GROSS.SQUARE.FEET)), 
    LAND.SQUARE.FEET = as.numeric(gsub("[^0-9]", "", LAND.SQUARE.FEET))    
  ) %>%
  filter(
    !is.na(SALE.PRICE) & SALE.PRICE > 0,             
    !is.na(GROSS.SQUARE.FEET) & GROSS.SQUARE.FEET > 0,  
    !is.na(LAND.SQUARE.FEET) & LAND.SQUARE.FEET > 0     

# Train-Test Split
set.seed(123)
train_index <- createDataPartition(data_clean$SALE.PRICE, p = 0.7, list = FALSE)
train_data <- data_clean[train_index, ]
test_data <- data_clean[-train_index, ]


train_features <- train_data %>%
  select(GROSS.SQUARE.FEET, LAND.SQUARE.FEET, TOTAL.UNITS, YEAR.BUILT)
train_labels <- train_data$BUILDING.CLASS.CATEGORY
test_features <- test_data %>%
  select(GROSS.SQUARE.FEET, LAND.SQUARE.FEET, TOTAL.UNITS, YEAR.BUILT)
test_labels <- test_data$BUILDING.CLASS.CATEGORY


train_data_clean <- na.omit(cbind(train_features, train_labels))
test_data_clean <- na.omit(cbind(test_features, test_labels))

# Extract cleaned features and labels
train_features_clean <- train_data_clean[, -ncol(train_data_clean)]
train_labels_clean <- train_data_clean[, ncol(train_data_clean)]
test_features_clean <- test_data_clean[, -ncol(test_data_clean)]
test_labels_clean <- test_data_clean[, ncol(test_data_clean)]

train_labels_clean <- factor(train_labels_clean)
test_labels_clean <- factor(test_labels_clean)

# k-NN Model =
knn_predictions <- knn(
  train = train_features_clean, 
  test = test_features_clean, 
  cl = train_labels_clean, 
  k = 5
)

# Naïve Bayes Model
nb_model <- naiveBayes(
  train_features_clean, 
  train_labels_clean
)

nb_predictions <- predict(nb_model, newdata = test_features_clean)


knn_conf_matrix <- confusionMatrix(knn_predictions, test_labels_clean)
nb_conf_matrix <- confusionMatrix(nb_predictions, test_labels_clean)

# Display confusion matrices for k-NN and Naïve Bayes
cat("\nk-NN Confusion Matrix:\n")
print(knn_conf_matrix)

cat("\nNaïve Bayes Confusion Matrix:\n")
print(nb_conf_matrix)

# Visualizations for Naïve Bayes and k-NN

# Boxplot of Actual vs Predicted Sale Prices (Log-Transformed) for k-NN and Naïve Bayes
ggplot() +
  geom_boxplot(aes(x = "Log Actual", y = log(test_data$SALE.PRICE)), fill = "blue", alpha = 0.5) +
  geom_boxplot(aes(x = "Log Predicted (k-NN)", y = log(as.numeric(knn_predictions))), fill = "green", alpha = 0.5) +
  geom_boxplot(aes(x = "Log Predicted (Naïve Bayes)", y = log(as.numeric(nb_predictions))), fill = "red", alpha = 0.5) +
  labs(
    title = "Boxplot of Log-Transformed Actual vs Predicted Sale Prices",
    x = "Type",
    y = "Log of Sale Price"
  ) +
  theme_minimal()

# Residual Density Plot (Actual - Predicted) for k-NN and Naïve Bayes
knn_residuals <- log(test_data$SALE.PRICE) - log(as.numeric(knn_predictions))
nb_residuals <- log(test_data$SALE.PRICE) - log(as.numeric(nb_predictions))

ggplot() +
  geom_density(aes(x = knn_residuals), fill = "blue", alpha = 0.5) +
  geom_density(aes(x = nb_residuals), fill = "red", alpha = 0.5) +
  labs(
    title = "Residual Density Plot (Actual - Predicted)",
    x = "Residuals (Actual - Predicted)",
    y = "Density"
  ) +
  theme_minimal()


